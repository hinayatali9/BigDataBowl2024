{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as opt\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import imageio\n",
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_features_l, in_features_g, attn_features, up_factor, normalize_attn=True):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.up_factor = up_factor\n",
    "        self.normalize_attn = normalize_attn\n",
    "        self.W_l = nn.Conv2d(in_channels=in_features_l, out_channels=attn_features, kernel_size=1, padding=0, bias=False)\n",
    "        self.W_g = nn.Conv2d(in_channels=in_features_g, out_channels=attn_features, kernel_size=1, padding=0, bias=False)\n",
    "        self.phi = nn.Conv2d(in_channels=attn_features, out_channels=1, kernel_size=1, padding=0, bias=True)\n",
    "        self.relu = nn.SiLU()\n",
    "    def forward(self, l, g):\n",
    "        #print(in_features_g)\n",
    "        N, C, W, H = l.shape\n",
    "        l_ = self.W_l(l)\n",
    "        g_ = self.W_g(g)\n",
    "        #print(g_.shape)\n",
    "        c = self.phi(self.relu(l_ + g_)) # batch_sizex1xWxH\n",
    "        #print(c.shape)\n",
    "        # compute attn map\n",
    "        if self.normalize_attn:\n",
    "            a = (c.view(N,1,-1)).view(N,1,W,H)\n",
    "        else:\n",
    "            a = torch.sigmoid(c)\n",
    "        # re-weight the local feature\n",
    "        f = torch.mul(a.expand_as(l), l) # batch_sizexCxWxH\n",
    "        if self.normalize_attn:\n",
    "            output = f.view(N,C,-1) # weighted sum\n",
    "        else:\n",
    "            output = nn.AdaptiveAvgPool2d(f, (1,1)).view(N,C) # global average pooling\n",
    "        return a, output\n",
    "    \n",
    "class Skynet1_4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv21 = nn.Conv2d(8,128,1,stride = 1)\n",
    "        self.conv22 = nn.Conv2d(128, 160, 1,stride = 1)\n",
    "        self.conv23 = nn.Conv2d(160,128, 1,stride = 1)\n",
    "        self.poolmax2 = nn.MaxPool2d(1,5)\n",
    "        self.poolavg2 = nn.AvgPool2d(1,5)\n",
    "\n",
    "        self.poolmax1 = nn.MaxPool1d(1,5)\n",
    "        self.poolavg1 = nn.AvgPool1d(1,5)\n",
    "        self.batch1 = nn.BatchNorm1d(2)\n",
    "\n",
    "        self.conv11 = nn.Conv1d(2,128,1)\n",
    "        self.batch2 = nn.BatchNorm1d(128)\n",
    "        self.conv12 = nn.Conv1d(128,160,1)\n",
    "        self.batch3 = nn.BatchNorm1d(160)\n",
    "        self.conv13 = nn.Conv1d(160,96,1)\n",
    "        self.batch4 = nn.BatchNorm1d(96)\n",
    "\n",
    "        self.attentionmech = AttentionBlock(8, 128, 256, 4, normalize_attn=True)\n",
    "        self.fc1 = nn.Linear(1920,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.batch6 = nn.BatchNorm1d(512)\n",
    "        self.batch5 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256,1)\n",
    "        #self.squeeze = torch.squeeze(1)\n",
    "        self.relu = nn.SiLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        temp = x\n",
    "        x = self.relu(self.conv21(x))\n",
    "        x = self.relu(self.conv22(x))\n",
    "        x = self.relu(self.conv23(x))\n",
    "        attention, x = self.attentionmech(temp,x)\n",
    "        xmax = self.poolmax2(x)\n",
    "        xavg = self.poolavg2(x)\n",
    "        x = 0.3*xmax + 0.7*xavg\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #x = torch.flatten(x,start_dim=2,end_dim=3)\n",
    "        x = self.batch1(x)\n",
    "        x = self.relu(self.conv11(x))\n",
    "        x = self.batch2(x)\n",
    "        x = self.relu(self.conv12(x))\n",
    "        x = self.batch3(x)\n",
    "        x = self.relu(self.conv13(x))\n",
    "        x = self.batch4(x)\n",
    "        xmax = self.poolmax1(x)\n",
    "        xavg = self.poolavg1(x)\n",
    "        x = 0.3*xmax + 0.7*xavg\n",
    "        x = torch.flatten(x,start_dim=1,end_dim=2)\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        #print(x.mT.shape)\n",
    "        x = self.batch6(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        #x = self.batch5(x.T)\n",
    "        x = self.fc3(x)\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(frame):\n",
    "    ballcarrier = 0\n",
    "    temp = torch.zeros(8,22,22)\n",
    "    for i in range(len(frame['x'])):\n",
    "        if frame.iloc[i,'is_on_offence']:\n",
    "            teamvec1 = frame['is_on_offence']\n",
    "            teamvec2 = frame['is_on_defence']\n",
    "        else:\n",
    "            teamvec2 = frame['is_on_offence']\n",
    "            teamvec1 = frame['is_on_defence']\n",
    "        if frame.iloc[i,\"is_ballcarrier\"]:\n",
    "            ballcarrier = i\n",
    "        x1 = frame.iloc[i,'x']\n",
    "        y1 = frame.iloc[i,'y']\n",
    "        s1 = frame.iloc[i,'s']\n",
    "        o1 = frame.iloc[i,'o']\n",
    "        dir1 = frame.iloc[i,'dir']\n",
    "        temp[0,0:-2,j] = torch.tensor((frame['x'] - x1).values)\n",
    "        temp[1,0:-2,j] = torch.tensor((frame['y'] - y1).values)\n",
    "        temp[2,0:-2,j] = torch.tensor((frame['s'] - s1).values)\n",
    "        temp[3,0:-2,j] = torch.tensor((frame['dir'] - dir1).values)\n",
    "        temp[3,0:-2,j] = temp[3,0:-2,j] - (temp[3,0:-2,j] > 360)*-360\n",
    "        temp[3,0:-2,j] = temp[3,0:-2,j] + (temp[3,0:-2,j] < 0)*-360\n",
    "        temp[4,0:-2,j] = torch.tensor((np.arctan2((frame['y'] - y1).to_numpy(), -1*(frame['x'] - x1).to_numpy())*180/np.pi))\n",
    "        temp[4,0:-2,j] = temp[4,0:-2,j] + (1*(-1*(frame['x'] - x1) > 0).values & (((frame['y'] - y1) < 0)*180).values) + (-1*(-1*(frame['x'] - x1) > 0).values & ((frame['y'] - y1) < 0).values)*180\n",
    "        temp[4,0:-2,j] = temp[4,0:-2,j] -360*(temp[4,0:-2,j] > 360)\n",
    "        temp[4,0:-2,j] = temp[4,0:-2,j] +360*(temp[4,0:-2,j] < 0)\n",
    "        temp[4,0:-2,j] -= o1\n",
    "        temp[5,0:-2,j] = torch.tensor((teamvec2*(((frame['x'] - x1)**2 + (frame['y'] - y1)**2)**0.5) - (~teamvec2)*(((frame['x'] - x1)**2 + (frame['y'] - y1)**2)**0.5)).values)\n",
    "        #temp2 = torch.zeros((2,22))\n",
    "        if y1 >= 53.3/2:\n",
    "            temp[:,i] = 53.3 - y1\n",
    "        else:\n",
    "            temp[:,i] = y1\n",
    "                                    \n",
    "        temp[-1,i] = 105 - x1\n",
    "    inds = temp[5,i,:].sort()[1]\n",
    "    temp = temp[:,:,inds]\n",
    "    temp = temp[:,inds,:]\n",
    "    return temp\n",
    "\n",
    "def predict(frame,model):\n",
    "    yards_predict, att = model.forward(reformat(frame))\n",
    "    return yards_predict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model, requires load file to be in same directory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Skynet1_4().to(device).eval()\n",
    "model.load_state_dict(torch.load(\"modelSkynet15-4fixed.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
