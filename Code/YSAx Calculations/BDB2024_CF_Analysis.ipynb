{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in All 9 weeks of Counterfactuals\n",
    "df1=pd.read_csv('EndZoneCFS_week1.csv', index_col=None)\n",
    "df2=pd.read_csv('EndZoneCFS_week2.csv', index_col=None)\n",
    "df3=pd.read_csv('EndZoneCFS_week3.csv', index_col=None)\n",
    "df4=pd.read_csv('EndZoneCFS_week4.csv', index_col=None)\n",
    "df5=pd.read_csv('EndZoneCFS_week5.csv', index_col=None)\n",
    "df6=pd.read_csv('EndZoneCFS_week6.csv', index_col=None)\n",
    "df7=pd.read_csv('EndZoneCFS_week7.csv', index_col=None)\n",
    "df8=pd.read_csv('EndZoneCFS_week8.csv', index_col=None)\n",
    "df9=pd.read_csv('EndZoneCFS_week9.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cat all 9 weeks of CounterFactuals into one Dataframe\n",
    "df_counterfactuals=pd.concat([df1,df2, df3, df4,df5,df6, df7,df8, df9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibrate the model predictions such that the sum of Yards Saved will come out to zero\n",
    "df_counterfactuals['Prediction Difference']=df_counterfactuals['Prediction Difference']*1.558\n",
    "df_counterfactuals['Original Prediction']=df_counterfactuals['Original Prediction']*1.558\n",
    "df_counterfactuals['Projected Prediction']=df_counterfactuals['Projected Prediction']*1.558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction of previous frame, and Yards remaining on previous frame\n",
    "df_counterfactuals['PrevPrediction']=df_counterfactuals.groupby(['gameId', 'playId', 'nflId'])['Original Prediction'].transform(lambda x: x.shift(1))\n",
    "df_counterfactuals['PrevYR']=df_counterfactuals.groupby(['gameId', 'playId', 'nflId'])['Yards Remaining'].transform(lambda x: x.shift(1))\n",
    "#Shift Prediction Differences by one frame\n",
    "df_counterfactuals['Prediction Difference-1']=df_counterfactuals.groupby(['gameId', 'playId', 'nflId'])['Prediction Difference'].transform(lambda x: x.shift(1))\n",
    "#Calculate Yards saved as previous predictionn - change in yards - current prediction\n",
    "df_counterfactuals['YardsSaved'] = df_counterfactuals['PrevPrediction'] - (df_counterfactuals['PrevYR'] - df_counterfactuals['Yards Remaining']) - df_counterfactuals['Original Prediction']\n",
    "#Remove nan from df\n",
    "df_counterfactuals=df_counterfactuals.loc[(df_counterfactuals['YardsSaved'].isna()==False) & (df_counterfactuals['Prediction Difference-1'].isna()==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group df_counterfactuals into individual frames\n",
    "frames = df_counterfactuals.groupby(['gameId', 'playId', 'frameId'])\n",
    "framelist1 = []\n",
    "\n",
    "for frame in tqdm(frames):\n",
    "\n",
    "    #Set negative counterfactuals to zero\n",
    "    frame[1].loc[frame[1]['Prediction Difference-1'] <= 0,'Prediction Difference-1'] = 0  \n",
    "    #If all counterfactuals are zero, assign credit to whole team.\n",
    "    if sum(frame[1].loc[:,'Prediction Difference-1']) == 0:\n",
    "        frame[1].loc[:,'Prediction Difference-1'] = 1\n",
    "    #Set sum of normalized YSAX to be equal to yards saved\n",
    "    x = (frame[1]['YardsSaved'].iloc[0])/sum((frame[1]['Prediction Difference-1']))\n",
    "    frame[1]['NormalizedYSAX'] = frame[1]['Prediction Difference-1']*x\n",
    "    #Add frame to list of frames, to be catted together later\n",
    "    framelist1 += [frame[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cat all frames back together, save into a csv\n",
    "results1 = pd.concat(framelist1, ignore_index=True)\n",
    "results1.to_csv('finalrankings.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in results of normalizing ysax\n",
    "results = pd.read_csv('finalrankings.csv')\n",
    "\n",
    "#Fill in any potential nans with zeros\n",
    "results['NormalizedYSAX'] = results['NormalizedYSAX'].fillna(0)\n",
    "\n",
    "#Read in tackle csv, set tackle value to be tackles + 0.5*assists - missed tackles\n",
    "tackles = pd.read_csv(os.path.join(os.path.join(\"Data\", str(2024)),\"tackles.csv\"))\n",
    "tacklesum = pd.DataFrame(tackles.groupby(['nflId'])['tackle'].sum()).sort_values(by='tackle', ascending=False).reset_index()\n",
    "assistsum = pd.DataFrame(tackles.groupby(['nflId'])['assist'].sum()).sort_values(by='assist', ascending=False).reset_index()\n",
    "missedsum = pd.DataFrame(tackles.groupby(['nflId'])['pff_missedTackle'].sum()).sort_values(by='pff_missedTackle', ascending=False).reset_index()\n",
    "totaltackles = [tacklesum,assistsum,missedsum]\n",
    "totaltackles = reduce(lambda left, right: pd.merge(left,right, on = ['nflId'], how = 'outer'),totaltackles).fillna(0)\n",
    "totaltackles['TackleValue'] = totaltackles['tackle'] + 0.5*totaltackles['assist'] - totaltackles['pff_missedTackle']\n",
    "\n",
    "#Sum normalized YSAX on over frames on plays\n",
    "results =pd.DataFrame({'NormalizedYSAX' : results.groupby(['nflId','playId'])['NormalizedYSAX'].sum()}).sort_values(by='NormalizedYSAX', ascending=False).reset_index()\n",
    "#Count number of snaps each player played in\n",
    "results['SnapCount'] = results.groupby(['nflId'])['nflId'].transform('count')\n",
    "#Sum results over plays\n",
    "results=pd.DataFrame({'NormalizedYSAX': results.groupby(['nflId'])['NormalizedYSAX'].sum(), 'SnapCount':results.groupby(['nflId'])['SnapCount'].sum()}).sort_values(by='NormalizedYSAX', ascending=False).reset_index()\n",
    "results['SnapCount'] = results['SnapCount']**0.5\n",
    "results = results[['NormalizedYSAX','nflId','SnapCount']]\n",
    "\n",
    "#Read in players csv\n",
    "players = pd.read_csv(os.path.join(os.path.join(\"Data\", str(2024)),\"players.csv\"))\n",
    "#Merge players, tackle value, and results into final csv\n",
    "rankings = players.merge(totaltackles[['nflId','TackleValue']], how='left', on=['nflId']).fillna(0)\n",
    "rankings = rankings.merge(results[['nflId','NormalizedYSAX','SnapCount']], how='left', on=['nflId']).fillna(0)\n",
    "#Filter out offensive players\n",
    "rankings = rankings[rankings['position'].isin(['CB', 'DB', 'DE', 'DT', 'FS', 'ILB', 'MLB', 'NT', 'OLB', 'SS'])]\n",
    "#Filter by Snap Count if needed\n",
    "#rankings = rankings[rankings['SnapCount'] > 0]\n",
    "#Calculate Values per snap\n",
    "rankings['TackleValue/Snap'] = rankings['TackleValue']/rankings['SnapCount']\n",
    "rankings['NormalizedYSAX/Snap'] = rankings['NormalizedYSAX']/rankings['SnapCount']\n",
    "#Remove extra columns\n",
    "rankings = rankings[['displayName','nflId','position','SnapCount','NormalizedYSAX','NormalizedYSAX/Snap','TackleValue','TackleValue/Snap']]\n",
    "#Sort by YSAX\n",
    "rankings = rankings.sort_values(by='NormalizedYSAX', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get LineBacker Rankings\n",
    "LB = rankings.loc[(rankings['position']=='ILB') | (rankings['position']=='OLB') | (rankings['position']=='MLB')]\n",
    "LB.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Defensive Back Rankings\n",
    "S = rankings.loc[(rankings['position']=='FS') | (rankings['position']=='SS') | (rankings['position']=='CB')]\n",
    "S.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Defensive Linemen Rankings\n",
    "DE = rankings.loc[(rankings['position']=='DT') | (rankings['position']=='NT') | (rankings['position']=='DE')].head(10)\n",
    "DE.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
