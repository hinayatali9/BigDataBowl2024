{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from preprocessing import get_tracking_and_plays, compute_feature_df, create_feature_tensor\n",
    "from model import PREPROCESS_STD, PREPROCESS_MEAN, load_expected_yards_model\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'nflId', 'gameId', 'playId', 'frameId', 'Yards Remaining',\n",
      "       'Original Prediction', 'Projected Prediction', 'Prediction Difference'],\n",
      "      dtype='object')\n",
      "11765.29178738594\n"
     ]
    }
   ],
   "source": [
    "week1 = pd.read_csv(\"CounterFactualsweek_1.csv\")\n",
    "print(week1.columns)\n",
    "print(sum(week1['Prediction Difference']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cur_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracking_with_plays(filepath):\n",
    "    tracking = pd.read_csv(filepath)\n",
    "    plays = pd.read_csv(\"plays.csv\")\n",
    "    tracking = tracking[tracking['playId'].isin(tracking[tracking['event'] != 'fumble']['playId'].unique())]\n",
    "    plays = plays[plays['playNullifiedByPenalty'] == 'N']\n",
    "    tracking.loc[tracking['playDirection'] == 'left', 'x'] = 120 - tracking.loc[tracking['playDirection'] == 'left', 'x']\n",
    "    tracking.loc[tracking['playDirection'] == 'left', 'y'] = (160/3) - tracking.loc[tracking['playDirection'] == 'left', 'y']\n",
    "    tracking.loc[tracking['playDirection'] == 'left', 'dir'] += 180\n",
    "    tracking.loc[tracking['dir'] > 360, 'dir'] -= 360\n",
    "    tracking.loc[tracking['playDirection'] == 'left', 'o'] += 180\n",
    "    tracking.loc[tracking['o'] > 360, 'o'] -= 360\n",
    "    tracking_with_plays = tracking.merge(plays, on=['gameId', 'playId'], how='left')\n",
    "    tracking_with_plays['is_on_offense'] = tracking_with_plays['club'] == tracking_with_plays['possessionTeam']\n",
    "    tracking_with_plays['is_on_defense'] = tracking_with_plays['club'] == tracking_with_plays['defensiveTeam']\n",
    "    tracking_with_plays['is_ballcarrier'] = tracking_with_plays['ballCarrierId'] == tracking_with_plays['nflId']\n",
    "    bc_coords=tracking_with_plays.loc[tracking_with_plays['is_ballcarrier']]\n",
    "    bc_coords['bc_x']=bc_coords['x']\n",
    "    bc_coords['bc_y']=bc_coords['y']\n",
    "    bc_coords=bc_coords[['gameId', 'playId', 'frameId', 'bc_x', 'bc_y']]\n",
    "    tracking_with_plays=tracking_with_plays.merge(bc_coords, on=['gameId', 'playId', 'frameId'], how='left')\n",
    "    end_frame = tracking_with_plays[tracking_with_plays['event'].isin(['tackle', 'out_of_bounds'])].groupby(['gameId', 'playId'])['frameId'].min().reset_index()\n",
    "    end_frame.rename(columns={'frameId': 'frameId_end'}, inplace=True)\n",
    "    start_frame = tracking_with_plays[tracking_with_plays['event'].isin(['run', 'lateral', 'run_pass_option', 'handoff', 'pass_arrived'])].groupby(['gameId', 'playId'])['frameId'].min().reset_index()\n",
    "    start_frame.rename(columns={'frameId': 'frameId_start'}, inplace=True)\n",
    "    tracking_with_plays = tracking_with_plays.merge(start_frame, on=['gameId', 'playId'], how='left')\n",
    "    tracking_with_plays = tracking_with_plays.merge(end_frame, on=['gameId', 'playId'], how='left')\n",
    "    tracking_with_plays = tracking_with_plays[(tracking_with_plays['frameId'] <= tracking_with_plays['frameId_end']) &\n",
    "                                              (tracking_with_plays['frameId'] >= tracking_with_plays['frameId_start'])]\n",
    "    return tracking_with_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tracking1['frameId'])//22,cur_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_tensors(files):\n",
    "    i = 1\n",
    "    for c in files:\n",
    "        print('Working on file ' + c)\n",
    "        tracking_with_play_train = get_tracking_and_plays(c)\n",
    "        feature_df_train = compute_feature_df(tracking_with_play_train)\n",
    "        input_tensor, target_tensor, reference_tensor = create_feature_tensor(feature_df_train)\n",
    "        np.save(f'week_{i}_full_x.npy', input_tensor)\n",
    "        np.save(f'week_{i}_full_y.npy', target_tensor)\n",
    "        np.save(f'week_{i}_full_r.npy', reference_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "create_input_tensors([os.path.join(os.path.join(\"Data\", str(2024)),\"tracking_week_\"+str(1) +\".csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_r = np.load(f'week_{1}_r_new.npy')\n",
    "print(len(np.unique(cur_r['gameId'])),len(cur_r['frameId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_arrays = []\n",
    "test_y_arrays = []\n",
    "test_r_arrays = []\n",
    "for i in range(1,10):\n",
    "    #print(i)\n",
    "    cur_x = np.load(f'week_{i}_x_new.npy')\n",
    "    cur_y = np.load(f'week_{i}_y_new.npy')\n",
    "    cur_r = np.load(f'week_{i}_r_new.npy')\n",
    "    test_x_arrays.append(cur_x)\n",
    "    test_y_arrays.append(cur_y)\n",
    "    test_r_arrays.append(cur_r)\n",
    "    print(np.unique(cur_r[:,0]))\n",
    "\n",
    "test_x_tensor = np.concatenate(test_x_arrays)\n",
    "test_y_tensor = np.concatenate(test_y_arrays)\n",
    "test_r_tensor = np.concatenate(test_r_arrays)\n",
    "print(len(np.unique(test_r_tensor[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.tensor(test_x_tensor, dtype=torch.float)\n",
    "test_y = torch.tensor(test_y_tensor, dtype=torch.float)\n",
    "test_r = torch.tensor(test_r_tensor, dtype=torch.int)\n",
    "\n",
    "# Normalize data according to training set mean\n",
    "test_x = (test_x - PREPROCESS_MEAN) / PREPROCESS_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(test_r[:,0])))\n",
    "print(len(np.unique(test_r_tensor[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(test_x, test_y, test_r)\n",
    "\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_expected_yards_model()\n",
    "model.eval()\n",
    "\n",
    "all_outputs = np.zeros((len(test_x), 5))\n",
    "cur = 0\n",
    "for cur_x, cur_y, cur_r in tqdm(test_loader):\n",
    "    cur_outputs = model(cur_x)\n",
    "    for i in range(len(cur_outputs)):\n",
    "        all_outputs[cur, 0] = cur_r[i][0]\n",
    "        all_outputs[cur, 1] = cur_r[i][1]\n",
    "        all_outputs[cur, 2] = cur_r[i][2]\n",
    "        all_outputs[cur, 3] = cur_outputs[i]\n",
    "        all_outputs[cur, 4] = cur_y[i]\n",
    "        cur+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs[-1]\n",
    "#sum(all_outputs[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_outputs, columns=['gameId', 'playId', 'frameId', 'ExpectedYards', 'ActualYards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ExpectedYards_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(df['ExpectedYards']),sum(df['ActualYards']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('bdb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63197cf8b3f0fe8121fde273e46f91e98e23cf99f6cb99d7435efd494125cddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
